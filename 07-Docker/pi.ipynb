{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26423319",
   "metadata": {},
   "source": [
    "### Monte Carlo Simulation\n",
    "One of the classic performance measurements for compute engines is the calculation of pi through Monte Carlo simulation. In this example:\n",
    "1. You will set up an ipyparallel cluster with maximum of 8 cores. \n",
    "2. Test if all cores in the cluster respond.\n",
    "3. Run Monte Carlo simulation through Python\n",
    "4. Run Monte Carlo simulation through Bodo\n",
    "\n",
    "At the end compare the Execution times. Bodo runs a bit faster than 8x. This is the power of bodo's compiler along with MPI and SPMD as part of the core compute engine. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7213c37e",
   "metadata": {},
   "source": [
    "### Run with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a434f4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 7.801251173019409 \n",
      " result: 3.14156896\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def calc_pi(number_of_samples):\n",
    "    t1 = time.time()\n",
    "    xx = 2 * np.random.ranf(number_of_samples) - 1\n",
    "    y = 2 * np.random.ranf(number_of_samples) - 1\n",
    "    pi = 4 * np.sum(xx ** 2 + y ** 2 < 1) / number_of_samples\n",
    "    print(\"Execution time:\", time.time() - t1, \"\\n result:\", pi)\n",
    "\n",
    "calc_pi(100_000_000)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8a515c",
   "metadata": {},
   "source": [
    "### Run with Bodo in Parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1398d7",
   "metadata": {},
   "source": [
    "To run this code with bodo, we need to add the @bodo.jit decorator on top of the same function. The argument of cache=True caches the compiled binary such that next time you run a code, there is no need to compile as long as the code text stays the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e07d4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.638517999999749 \n",
      " result: 3.14187308\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import bodo\n",
    "\n",
    "@bodo.jit(spawn=True, cache=True)\n",
    "def calc_pi(number_of_samples):\n",
    "    t1 = time.time()\n",
    "    xx = 2 * np.random.ranf(number_of_samples) - 1\n",
    "    y = 2 * np.random.ranf(number_of_samples) - 1\n",
    "    pi = 4 * np.sum(xx ** 2 + y ** 2 < 1) / number_of_samples\n",
    "    print(\"Execution time:\", time.time() - t1, \"\\n result:\", pi)\n",
    "\n",
    "calc_pi(100_000_000)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efedfad4",
   "metadata": {},
   "source": [
    "### Scale Up Easily\n",
    "With this amazing speed up, you can handle much larger data. Let's increase our simulation size by 100x. If run this with python, we would expect 100 times longer runtime as we saw with python (e.g., 400 sec). But run this code cell below and see it will run for about 45 sec (on an M1 Macbook Pro). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2473fe2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 45.96997599999986 \n",
      " result: 3.1415985968\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import bodo\n",
    "\n",
    "@bodo.jit(spawn=True, cache=True)\n",
    "def calc_pi(number_of_samples):\n",
    "    t1 = time.time()\n",
    "    xx = 2 * np.random.ranf(number_of_samples) - 1\n",
    "    y = 2 * np.random.ranf(number_of_samples) - 1\n",
    "    pi = 4 * np.sum(xx ** 2 + y ** 2 < 1) / number_of_samples\n",
    "    print(\"Execution time:\", time.time() - t1, \"\\n result:\", pi)\n",
    "\n",
    "calc_pi(100 * 100_000_000)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
